- predictに使うcsvの長さで、結果が変わる
  - 理由は不明
- backtestsの結果と、predictionsの結果を比較
  - labelsの部分の食い違いを見たい
- 1:1:1の割合になるように調整したほうがいい？
  - ↓の状態
  
```
label=0の割合: 30.73%
label=1の割合: 31.47%
label=2の割合: 37.81%
```


- 相関（学習への寄与度）が大きすぎるものは除外したほうが安定する？
- 学習期間は長いほうが良い
- extra_treesを入れたほうが良いのかは不明


- 直接的な相関が強い指標は使わない
- その上で、汎化の量を調整していく
  - 汎化しているほうから、非汎化の方へ調整していく
  - 'fraction'系のパラメータ
  - 非汎化させていくと、どこかでバックテストがよくなる値域がある
  - logloss 0.9くらい？